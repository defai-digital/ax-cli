/**
 * Usage Command Handler
 *
 * Handler for /usage - API usage statistics and cost estimates
 *
 * @packageDocumentation
 */

import type { CommandDefinition, CommandContext, CommandResult } from "../types.js";
import { getUsageTracker } from "../../utils/usage-tracker.js";

/**
 * Session statistics interface
 */
interface SessionStats {
  totalRequests: number;
  totalPromptTokens: number;
  totalCompletionTokens: number;
  totalTokens: number;
  totalReasoningTokens: number;
  byModel: Map<string, { totalTokens: number; requests: number }>;
}

/**
 * Format Grok-specific usage information
 */
function formatGrokUsageInfo(stats: SessionStats, currentModel: string): string {
  let content = `\n**ðŸ”‘ xAI Account Usage & Limits:**\n`;
  content += `  âš ï¸  API does not provide programmatic access to usage data\n`;
  content += `\n  **Check your account:**\n`;
  content += `  â€¢ Usage Explorer: https://console.x.ai\n`;
  content += `  â€¢ Billing & Team: https://console.x.ai/team\n`;
  content += `  â€¢ API Keys: https://console.x.ai/api-keys\n`;

  content += `\n**â„¹ï¸  Notes:**\n`;
  content += `  â€¢ Usage is tracked in real-time on the xAI console\n`;
  content += `  â€¢ Cached input tokens: 75% discount\n`;

  // Grok pricing based on model
  const modelLower = currentModel.toLowerCase();
  if (modelLower.includes("grok-4.1-fast")) {
    content += `\n**ðŸ’° Grok 4.1 Fast Pricing:**\n`;
    content += `  â€¢ Input: $0.20 per 1M tokens\n`;
    content += `  â€¢ Output: $0.50 per 1M tokens\n`;
  } else {
    content += `\n**ðŸ’° Grok 4 Pricing:**\n`;
    content += `  â€¢ Input: $3.00 per 1M tokens\n`;
    content += `  â€¢ Output: $15.00 per 1M tokens\n`;
    content += `  â€¢ Cached: $0.75 per 1M tokens\n`;
  }

  if (stats.totalRequests > 0) {
    // Calculate estimated cost based on model
    let inputRate = 3.0;
    let outputRate = 15.0;
    if (modelLower.includes("grok-4.1-fast")) {
      inputRate = 0.2;
      outputRate = 0.5;
    }
    const inputCost = (stats.totalPromptTokens / 1000000) * inputRate;
    const outputCost = (stats.totalCompletionTokens / 1000000) * outputRate;
    const totalCost = inputCost + outputCost;
    content += `\n**ðŸ’µ Estimated Session Cost:**\n`;
    content += `  â€¢ Input: $${inputCost.toFixed(6)} (${stats.totalPromptTokens.toLocaleString()} tokens)\n`;
    content += `  â€¢ Output: $${outputCost.toFixed(6)} (${stats.totalCompletionTokens.toLocaleString()} tokens)\n`;
    content += `  â€¢ **Total: ~$${totalCost.toFixed(6)}**\n`;
  }

  return content;
}

/**
 * Format GLM-specific usage information
 */
function formatGLMUsageInfo(stats: SessionStats): string {
  let content = `\n**ðŸ”‘ Z.AI Account Usage & Limits:**\n`;
  content += `  âš ï¸  API does not provide programmatic access to usage data\n`;
  content += `\n  **Check your account:**\n`;
  content += `  â€¢ Billing & Usage: https://z.ai/manage-apikey/billing\n`;
  content += `  â€¢ Rate Limits: https://z.ai/manage-apikey/rate-limits\n`;
  content += `  â€¢ API Keys: https://z.ai/manage-apikey/apikey-list\n`;

  content += `\n**â„¹ï¸  Notes:**\n`;
  content += `  â€¢ Billing reflects previous day (n-1) consumption\n`;
  content += `  â€¢ Current day usage may not be immediately visible\n`;
  content += `  â€¢ Cached content: 1/5 of original price\n`;

  content += `\n**ðŸ’° GLM Pricing:**\n`;
  content += `  â€¢ Input: $2.00 per 1M tokens\n`;
  content += `  â€¢ Output: $10.00 per 1M tokens\n`;
  content += `  â€¢ Cached: $0.50 per 1M tokens\n`;

  if (stats.totalRequests > 0) {
    // Calculate estimated cost for this session
    const inputCost = (stats.totalPromptTokens / 1000000) * 2.0;
    const outputCost = (stats.totalCompletionTokens / 1000000) * 10.0;
    const totalCost = inputCost + outputCost;
    content += `\n**ðŸ’µ Estimated Session Cost:**\n`;
    content += `  â€¢ Input: $${inputCost.toFixed(6)} (${stats.totalPromptTokens.toLocaleString()} tokens)\n`;
    content += `  â€¢ Output: $${outputCost.toFixed(6)} (${stats.totalCompletionTokens.toLocaleString()} tokens)\n`;
    content += `  â€¢ **Total: ~$${totalCost.toFixed(6)}**\n`;
  }

  return content;
}

/**
 * /usage command handler
 */
export function handleUsage(_args: string, ctx: CommandContext): CommandResult {
  const tracker = getUsageTracker();
  const stats = tracker.getSessionStats();
  const isGrok = ctx.provider.name === "grok";
  const currentModel = ctx.settings.getCurrentModel() || ctx.provider.defaultModel;

  const providerName = isGrok ? "xAI (Grok)" : "Z.AI (GLM)";
  let content = `ðŸ“Š **API Usage & Limits (${providerName})**\n\n`;

  // Session statistics
  content += "**ðŸ“± Current Session:**\n";
  content += `  â€¢ Model: ${currentModel}\n`;

  if (stats.totalRequests === 0) {
    content += "  No API requests made yet. Ask me something to start tracking!\n";
  } else {
    content += `  â€¢ Requests: ${stats.totalRequests.toLocaleString()}\n`;
    content += `  â€¢ Prompt Tokens: ${stats.totalPromptTokens.toLocaleString()}\n`;
    content += `  â€¢ Completion Tokens: ${stats.totalCompletionTokens.toLocaleString()}\n`;
    content += `  â€¢ Total Tokens: ${stats.totalTokens.toLocaleString()}\n`;

    if (stats.totalReasoningTokens > 0) {
      content += `  â€¢ Reasoning Tokens: ${stats.totalReasoningTokens.toLocaleString()}\n`;
    }

    if (stats.byModel.size > 0) {
      content += `\n  **Models Used:**\n`;
      for (const [model, modelStats] of stats.byModel.entries()) {
        content += `    - ${model}: ${modelStats.totalTokens.toLocaleString()} tokens (${modelStats.requests} requests)\n`;
      }
    }
  }

  // Provider-specific information
  if (isGrok) {
    content += formatGrokUsageInfo(stats, currentModel);
  } else {
    content += formatGLMUsageInfo(stats);
  }

  return {
    handled: true,
    entries: [
      {
        type: "assistant",
        content,
        timestamp: new Date(),
      },
    ],
    clearInput: true,
  };
}

/**
 * Usage command definition for registration
 */
export const usageCommands: CommandDefinition[] = [
  {
    name: "usage",
    description: "Show API usage statistics",
    category: "info",
    handler: handleUsage,
  },
];
